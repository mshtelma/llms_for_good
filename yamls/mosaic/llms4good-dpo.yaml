name: llm4good-llama3-8b-vegi
image: mosaicml/llm-foundry:2.3.0_cu121_flash2-latest
gpu_num: 16
cluster: r7z22p1

run_name:
scheduling:
  priority: lowest
  max_retries: 0
  preemptible: false
  watchdog_enabled: false

integrations:
  - integration_type: git_repo
    git_repo: mshtelma/llms_for_good
    git_branch: msh_dev
    pip_install: -e .
    path: /workspace/llm4good

command: |
  cd /workspace/llm4good
  pip install -r requirements.txt
  python llmsforgood/train_dpo.py --download_dataset --dataset_path /Volumes/msh/rlaif/data/training/ift/hf_dataset/    
  accelerate launch --config_file yamls/accelerate/zero2.yaml --num_processes 16 --num_machines 2 --machine_rank $NODE_RANK --main_process_ip $MASTER_ADDR --main_process_port $MASTER_PORT llmsforgood/train_dpo.py  --train  --model_run_id 3f35ec207b104a5ebcf12e596868f04e   --model_checkpoint llm4good-llama3-8b-vegi-ift-rsxPas/checkpoints/huggingface/ba66    
    
