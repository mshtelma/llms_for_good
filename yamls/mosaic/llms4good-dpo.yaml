name: llm4good-llama3-8b-vegi
image: mosaicml/llm-foundry:2.3.0_cu121_flash2-latest
gpu_num: 8
cluster: r14z3

run_name:
scheduling:
  priority: lowest
  max_retries: 0
  preemptible: false
  watchdog_enabled: false

integrations:
  - integration_type: git_repo
    git_repo: mshtelma/llms_for_good
    git_branch: msh_dev
    pip_install: -e .
    path: /workspace/llm4good

command: |
  cd /workspace/llm4good
  pip install -r requirements.txt
  python llmsforgood/train_dpo.py --download_dataset --dataset_path /Volumes/msh/rlaif/data/training/ift/hf_dataset/    
  python llmsforgood/train_dpo.py --download_model --model_run_id 3f35ec207b104a5ebcf12e596868f04e  --model_checkpoint llm4good-llama3-8b-vegi-ift-rsxPas/checkpoints/huggingface/ba66
  accelerate launch --config_file yamls/accelerate/zero2.yaml llmsforgood/train_dpo.py --train --per_device_train_batch_size 4 --num_train_epochs 1 --dataset_sample_size 100
 
    
